{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, h5py\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = h5py.File('./PersistenceDiagrams/jetPDs_Mass60-95_pT250-300_R1.25_Pix25.hdf5','r')\n",
    "csv_file = open('./Statistics/t-statistic.csv','r')\n",
    "totnum = len(dset['pd_birth'])\n",
    "\n",
    "reader = csv.reader(csv_file, delimiter=' ', quotechar='|')\n",
    "t = np.array([])\n",
    "for row in reader:\n",
    "    t = np.append(t, float(row[0]))\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(totnum):\n",
    "    \n",
    "    tstat = t[i] \n",
    "    jet_delta_R = dset['jet_delta_R'][i]\n",
    "    jet_eta = dset['jet_eta'][i]\n",
    "    jet_mass = dset['jet_mass'][i]\n",
    "    jet_phi = dset['jet_phi'][i]\n",
    "    jet_pt = dset['jet_pt'][i]\n",
    "    tau_1 = dset['tau_1'][i]\n",
    "    tau_2 = dset['tau_2'][i]\n",
    "    tau_21 = dset['tau_21'][i]\n",
    "    tau_3 = dset['tau_3'][i]\n",
    "    tau_32 = dset['tau_32'][i]\n",
    "    \n",
    "    X.append(np.array([tstat, jet_delta_R,jet_eta,jet_mass,jet_phi,jet_pt,tau_1,tau_2,tau_21,tau_3,tau_32]))\n",
    "    #X.append(np.array([tstat, jet_mass, tau_21]))\n",
    "    #X.append(np.array([jet_mass, tau_21]))\n",
    "    y.append(int(dset['signal'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 500, criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X[:2000],y[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15025697 0.07241742 0.05349153 0.14117368 0.05180827 0.06047246\n",
      " 0.0750006  0.07501698 0.14675138 0.10404257 0.06956813]\n"
     ]
    }
   ],
   "source": [
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = clf.predict_proba(X)\n",
    "csv_file = open('./Statistics/rf-statistic.csv','w')\n",
    "csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "for j in range(len(output)):\n",
    "    csv_writer.writerow([output[j][1]])\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
